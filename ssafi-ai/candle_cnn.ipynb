{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터와 라벨을 저장할 리스트 초기화\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "def make_dataset(dir_path, label):\n",
    "    image_files = [f for f in os.listdir(dir_path) if f.endswith('.png')]\n",
    "    \n",
    "    # 이미지 파일 반복 처리\n",
    "    for image_file in image_files:\n",
    "        # 이미지 파일 경로 생성\n",
    "        image_path = os.path.join(dir_path, image_file)\n",
    "        \n",
    "        # 이미지 읽기 (OpenCV 사용)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # 이미지 크기 조정 (필요한 경우)\n",
    "        # image = cv2.resize(image, (width, height))\n",
    "        \n",
    "        # 이미지 데이터와 라벨 추가\n",
    "        data.append(image)\n",
    "        labels.append(label)  # 클래스 라벨을 적절하게 설정해야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22787, 100, 100, 3)\n",
      "(22787,)\n"
     ]
    }
   ],
   "source": [
    "data_dir_0 = \"C:/ssafy/candle/0/\"\n",
    "data_dir_1 = \"C:/ssafy/candle/1/\"\n",
    "\n",
    "make_dataset(data_dir_0, 0)\n",
    "make_dataset(data_dir_1, 1)\n",
    "\n",
    "# 데이터와 라벨을 NumPy 배열로 변환\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 라벨을 원-핫 인코딩 (필요한 경우)\n",
    "# labels = to_categorical(labels)\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "570/570 [==============================] - 28s 48ms/step - loss: 0.7184 - accuracy: 0.5504 - val_loss: 0.6797 - val_accuracy: 0.5472\n",
      "Epoch 2/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6706 - accuracy: 0.5710 - val_loss: 0.6800 - val_accuracy: 0.5577\n",
      "Epoch 3/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6617 - accuracy: 0.5905 - val_loss: 0.6844 - val_accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6529 - accuracy: 0.6037 - val_loss: 0.6876 - val_accuracy: 0.5410\n",
      "Epoch 5/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6455 - accuracy: 0.6180 - val_loss: 0.7021 - val_accuracy: 0.5489\n",
      "Epoch 6/10\n",
      "570/570 [==============================] - 27s 48ms/step - loss: 0.6396 - accuracy: 0.6266 - val_loss: 0.6951 - val_accuracy: 0.5344\n",
      "Epoch 7/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6322 - accuracy: 0.6337 - val_loss: 0.7047 - val_accuracy: 0.5454\n",
      "Epoch 8/10\n",
      "570/570 [==============================] - 27s 48ms/step - loss: 0.6241 - accuracy: 0.6450 - val_loss: 0.7135 - val_accuracy: 0.5358\n",
      "Epoch 9/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6165 - accuracy: 0.6556 - val_loss: 0.7271 - val_accuracy: 0.5445\n",
      "Epoch 10/10\n",
      "570/570 [==============================] - 27s 47ms/step - loss: 0.6084 - accuracy: 0.6659 - val_loss: 0.7239 - val_accuracy: 0.5467\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 데이터 스케일링 (0~1 범위로)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_val = X_val.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# 클래스 수 계산 (예: 이진 분류)\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# CNN 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssafi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
